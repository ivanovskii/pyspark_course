{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aAfBJ5OQhcTu",
    "outputId": "e7e969ef-a910-4d70-a30d-c0ebd6d0f198"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\admin\\desktop\\pyspark\\venv\\lib\\site-packages (3.5.1)\n",
      "Requirement already satisfied: findspark in c:\\users\\admin\\desktop\\pyspark\\venv\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\admin\\desktop\\pyspark\\venv\\lib\\site-packages (from pyspark) (0.10.9.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "BNdat6SPhiEH"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "conf = SparkConf().set('spark.ui.port', '4050').set('spark.serializer', 'org.apache.spark.serializer.KryoSerializer')\\\n",
    "                  .set('spark.dynamicAllocation.enabled', 'true')\\\n",
    "                  .set('spark.shuffle.service.enabled', 'true') #трекер, чтобы возвращать ресурсы\n",
    "sc = SparkContext(conf=conf)\n",
    "spark = SparkSession.builder.master('local[*]').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FZORGQJAkELA"
   },
   "source": [
    "Анализировать будет датасет отсюда https://www.kaggle.com/shelvigarg/credit-card-buyers\n",
    "\n",
    "Definition\n",
    "\n",
    "ID - Unique Identifier for a row\n",
    "\n",
    "Gender - Gender of the Customer\n",
    "\n",
    "Age - Age of the Customer (in Years)\n",
    "\n",
    "Region_Code - Code of the Region for the customers\n",
    "\n",
    "Occupation - Occupation Type for the customer\n",
    "\n",
    "Channel_Code - Acquisition Channel Code for the Customer (Encoded)\n",
    "\n",
    "Vintage - Vintage for the Customer (In Months)\n",
    "\n",
    "Credit_Product - If the Customer has any active credit product (Home loan Personal loan, Credit Card etc.)\n",
    "\n",
    "AvgAccountBalance - Average Account Balance for the Customer in last 12 Months\n",
    "\n",
    "Is_Active - If the Customer is Active in last 3 Months"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YIgE50bSlRBK"
   },
   "source": [
    "Загрузим данные и посмотрим, что там внутри"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "tsUQHB1FjhPO"
   },
   "outputs": [],
   "source": [
    "data = spark.read.csv('credit_card_data.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YbvoQA6clcY-",
    "outputId": "05312b42-f87b-465c-dce1-794043a577b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Region_Code: string (nullable = true)\n",
      " |-- Occupation: string (nullable = true)\n",
      " |-- Channel_Code: string (nullable = true)\n",
      " |-- Vintage: integer (nullable = true)\n",
      " |-- Credit_Product: string (nullable = true)\n",
      " |-- Avg_Account_Balance: integer (nullable = true)\n",
      " |-- Is_Active: string (nullable = true)\n",
      " |-- Is_Lead: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4_sCeIsAlPoS",
    "outputId": "0a143318-853f-4894-c075-96a6741ce94e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+---+-----------+-------------+------------+-------+--------------+-------------------+---------+-------+\n",
      "|      ID|Gender|Age|Region_Code|   Occupation|Channel_Code|Vintage|Credit_Product|Avg_Account_Balance|Is_Active|Is_Lead|\n",
      "+--------+------+---+-----------+-------------+------------+-------+--------------+-------------------+---------+-------+\n",
      "|NNVBBKZB|Female| 73|      RG268|        Other|          X3|     43|            No|            1045696|       No|      0|\n",
      "|IDD62UNG|Female| 30|      RG277|     Salaried|          X1|     32|            No|             581988|       No|      0|\n",
      "|HD3DSEMC|Female| 56|      RG268|Self_Employed|          X3|     26|            No|            1484315|      Yes|      0|\n",
      "|BF3NC7KV|  Male| 34|      RG270|     Salaried|          X1|     19|            No|             470454|       No|      0|\n",
      "|TEASRWXV|Female| 30|      RG282|     Salaried|          X1|     33|            No|             886787|       No|      0|\n",
      "|ACUTYTWS|  Male| 56|      RG261|Self_Employed|          X1|     32|            No|             544163|      Yes|      0|\n",
      "|ETQCZFEJ|  Male| 62|      RG282|        Other|          X3|     20|          NULL|            1056750|      Yes|      1|\n",
      "|JJNJUQMQ|Female| 48|      RG265|Self_Employed|          X3|     13|            No|             444724|      Yes|      0|\n",
      "|ZMQFYKCB|Female| 40|      RG283|Self_Employed|          X2|     38|            No|            1274284|       No|      0|\n",
      "|NVKTFBA2|Female| 55|      RG268|Self_Employed|          X2|     49|           Yes|            2014239|       No|      0|\n",
      "|NVC424KZ|  Male| 53|      RG254|Self_Employed|          X3|    123|            No|             980664|      Yes|      0|\n",
      "|GZ5TMYIR|  Male| 27|      RG270|Self_Employed|          X1|     14|           Yes|             502787|       No|      0|\n",
      "|FCPEEIY3|Female| 27|      RG277|     Salaried|          X1|     20|            No|             811591|      Yes|      0|\n",
      "|KCE7JSFN|  Male| 31|      RG254|     Salaried|          X1|     31|           Yes|             938754|       No|      0|\n",
      "|EMEEHHBK|  Male| 79|      RG277|        Other|          X3|     57|            No|             832185|      Yes|      0|\n",
      "|UJ2NJKKL|  Male| 33|      RG268|Self_Employed|          X2|     69|          NULL|             517063|      Yes|      1|\n",
      "|CNGSPYWS|Female| 46|      RG268|        Other|          X3|     97|           Yes|            2282502|       No|      1|\n",
      "|VH7NBNNQ|Female| 59|      RG283|        Other|          X3|     15|           Yes|            2384692|       No|      1|\n",
      "|HDNJXDWC|Female| 65|      RG277|        Other|          X2|     20|            No|             341573|      Yes|      0|\n",
      "|BDOKI4CP|Female| 37|      RG269|        Other|          X1|     63|            No|             633484|      Yes|      0|\n",
      "+--------+------+---+-----------+-------------+------------+-------+--------------+-------------------+---------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KXN0MI0xlx3N"
   },
   "source": [
    "Посмотрим различные базовые вещи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "j3wkDh42mATz"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col,isnan, when, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YeJKCEzbmErU",
    "outputId": "5380d6bf-503b-49e8-9dbf-168c777dc7be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---+-----------+----------+------------+-------+--------------+-------------------+---------+-------+\n",
      "| ID|Gender|Age|Region_Code|Occupation|Channel_Code|Vintage|Credit_Product|Avg_Account_Balance|Is_Active|Is_Lead|\n",
      "+---+------+---+-----------+----------+------------+-------+--------------+-------------------+---------+-------+\n",
      "|  0|     0|  0|          0|         0|           0|      0|         29325|                  0|        0|      0|\n",
      "+---+------+---+-----------+----------+------------+-------+--------------+-------------------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in data.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dika1L3qmLuF"
   },
   "source": [
    "Пропуски только в кредитном продукте, логично заметь на тип, что кредита нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w20frxn8m3Nw",
    "outputId": "df1135bb-2b42-4aea-8d24-b59fa2f0b973"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------+\n",
      "|Credit_Product| count|\n",
      "+--------------+------+\n",
      "|          NULL| 29325|\n",
      "|            No|144357|\n",
      "|           Yes| 72043|\n",
      "+--------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select(col('Credit_Product')).groupBy('Credit_Product').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "PhfHAQs8mKmn"
   },
   "outputs": [],
   "source": [
    "data = data.fillna({'Credit_Product': 'No'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b6fVb5RAnQ2u"
   },
   "source": [
    "Проверим"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q8T1WGqSnSR-",
    "outputId": "2ad1250e-e0ef-46f7-c858-9bd7c10f58cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------+\n",
      "|Credit_Product| count|\n",
      "+--------------+------+\n",
      "|            No|173682|\n",
      "|           Yes| 72043|\n",
      "+--------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select(col('Credit_Product')).groupBy('Credit_Product').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KtDur_eFnU9M"
   },
   "source": [
    "Посмотри на данные с точки зрения дисбаланса классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PtIMjIMbnisg",
    "outputId": "66266ab9-a2b6-4bcb-80db-734256f7b7f0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "245725"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "qyX_QHI9oKfP"
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZFJ2i3UklxJH",
    "outputId": "5f76831f-e5cc-4256-a266-72e9ddfcb342"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|Is_Lead|count|\n",
      "+-------+-----+\n",
      "|      1| 0.24|\n",
      "|      0| 0.76|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select(col('Is_Lead'))\\\n",
    "    .groupBy('Is_Lead')\\\n",
    "    .count()\\\n",
    "    .withColumn('count', F.round(col('count') / data.count(), 2))\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8C4-7JsCotMW"
   },
   "source": [
    "Ладно, достаточно, мы тут сейчас говорим про MLlib, всякие анализы - тема прошлого семинара"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hFW-5rVezUzj"
   },
   "source": [
    "**Некоторые преобразования данных**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DIVOhaAJ2MYW"
   },
   "source": [
    "Начнем с простой обработки категориальных переменных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Ol8QdvOIza7d"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, IndexToString, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VPOBb0j_zrmL",
    "outputId": "bbe060cd-1216-4b23-b8f5-a8505ffbc2f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+---+-----------+-------------+------------+-------+--------------+-------------------+---------+-------+-----------+\n",
      "|      ID|Gender|Age|Region_Code|   Occupation|Channel_Code|Vintage|Credit_Product|Avg_Account_Balance|Is_Active|Is_Lead|GenderIndex|\n",
      "+--------+------+---+-----------+-------------+------------+-------+--------------+-------------------+---------+-------+-----------+\n",
      "|NNVBBKZB|Female| 73|      RG268|        Other|          X3|     43|            No|            1045696|       No|      0|        1.0|\n",
      "|IDD62UNG|Female| 30|      RG277|     Salaried|          X1|     32|            No|             581988|       No|      0|        1.0|\n",
      "|HD3DSEMC|Female| 56|      RG268|Self_Employed|          X3|     26|            No|            1484315|      Yes|      0|        1.0|\n",
      "|BF3NC7KV|  Male| 34|      RG270|     Salaried|          X1|     19|            No|             470454|       No|      0|        0.0|\n",
      "|TEASRWXV|Female| 30|      RG282|     Salaried|          X1|     33|            No|             886787|       No|      0|        1.0|\n",
      "|ACUTYTWS|  Male| 56|      RG261|Self_Employed|          X1|     32|            No|             544163|      Yes|      0|        0.0|\n",
      "|ETQCZFEJ|  Male| 62|      RG282|        Other|          X3|     20|            No|            1056750|      Yes|      1|        0.0|\n",
      "|JJNJUQMQ|Female| 48|      RG265|Self_Employed|          X3|     13|            No|             444724|      Yes|      0|        1.0|\n",
      "|ZMQFYKCB|Female| 40|      RG283|Self_Employed|          X2|     38|            No|            1274284|       No|      0|        1.0|\n",
      "|NVKTFBA2|Female| 55|      RG268|Self_Employed|          X2|     49|           Yes|            2014239|       No|      0|        1.0|\n",
      "|NVC424KZ|  Male| 53|      RG254|Self_Employed|          X3|    123|            No|             980664|      Yes|      0|        0.0|\n",
      "|GZ5TMYIR|  Male| 27|      RG270|Self_Employed|          X1|     14|           Yes|             502787|       No|      0|        0.0|\n",
      "|FCPEEIY3|Female| 27|      RG277|     Salaried|          X1|     20|            No|             811591|      Yes|      0|        1.0|\n",
      "|KCE7JSFN|  Male| 31|      RG254|     Salaried|          X1|     31|           Yes|             938754|       No|      0|        0.0|\n",
      "|EMEEHHBK|  Male| 79|      RG277|        Other|          X3|     57|            No|             832185|      Yes|      0|        0.0|\n",
      "|UJ2NJKKL|  Male| 33|      RG268|Self_Employed|          X2|     69|            No|             517063|      Yes|      1|        0.0|\n",
      "|CNGSPYWS|Female| 46|      RG268|        Other|          X3|     97|           Yes|            2282502|       No|      1|        1.0|\n",
      "|VH7NBNNQ|Female| 59|      RG283|        Other|          X3|     15|           Yes|            2384692|       No|      1|        1.0|\n",
      "|HDNJXDWC|Female| 65|      RG277|        Other|          X2|     20|            No|             341573|      Yes|      0|        1.0|\n",
      "|BDOKI4CP|Female| 37|      RG269|        Other|          X1|     63|            No|             633484|      Yes|      0|        1.0|\n",
      "+--------+------+---+-----------+-------------+------------+-------+--------------+-------------------+---------+-------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gender_indexer = StringIndexer(inputCol=\"Gender\", outputCol=\"GenderIndex\")\n",
    "gender_indexer = gender_indexer.fit(data)\n",
    "data = gender_indexer.transform(data)\n",
    "\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZAW5y21P0y7e",
    "outputId": "9a9e5d35-e33c-4575-c751-4784c5bdfbf3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Male', 'Female']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_indexer.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EwrZceE71Xwk"
   },
   "source": [
    "Обратная трансформация доступна через метод"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nWclZb5s08ay",
    "outputId": "51fd9730-f88d-43f3-f32d-0f75b5214157"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+---+-----------+-------------+------------+-------+--------------+-------------------+---------+-------+-----------+--------------+\n",
      "|      ID|Gender|Age|Region_Code|   Occupation|Channel_Code|Vintage|Credit_Product|Avg_Account_Balance|Is_Active|Is_Lead|GenderIndex|originalGender|\n",
      "+--------+------+---+-----------+-------------+------------+-------+--------------+-------------------+---------+-------+-----------+--------------+\n",
      "|NNVBBKZB|Female| 73|      RG268|        Other|          X3|     43|            No|            1045696|       No|      0|        1.0|        Female|\n",
      "|IDD62UNG|Female| 30|      RG277|     Salaried|          X1|     32|            No|             581988|       No|      0|        1.0|        Female|\n",
      "|HD3DSEMC|Female| 56|      RG268|Self_Employed|          X3|     26|            No|            1484315|      Yes|      0|        1.0|        Female|\n",
      "|BF3NC7KV|  Male| 34|      RG270|     Salaried|          X1|     19|            No|             470454|       No|      0|        0.0|          Male|\n",
      "|TEASRWXV|Female| 30|      RG282|     Salaried|          X1|     33|            No|             886787|       No|      0|        1.0|        Female|\n",
      "|ACUTYTWS|  Male| 56|      RG261|Self_Employed|          X1|     32|            No|             544163|      Yes|      0|        0.0|          Male|\n",
      "|ETQCZFEJ|  Male| 62|      RG282|        Other|          X3|     20|            No|            1056750|      Yes|      1|        0.0|          Male|\n",
      "|JJNJUQMQ|Female| 48|      RG265|Self_Employed|          X3|     13|            No|             444724|      Yes|      0|        1.0|        Female|\n",
      "|ZMQFYKCB|Female| 40|      RG283|Self_Employed|          X2|     38|            No|            1274284|       No|      0|        1.0|        Female|\n",
      "|NVKTFBA2|Female| 55|      RG268|Self_Employed|          X2|     49|           Yes|            2014239|       No|      0|        1.0|        Female|\n",
      "|NVC424KZ|  Male| 53|      RG254|Self_Employed|          X3|    123|            No|             980664|      Yes|      0|        0.0|          Male|\n",
      "|GZ5TMYIR|  Male| 27|      RG270|Self_Employed|          X1|     14|           Yes|             502787|       No|      0|        0.0|          Male|\n",
      "|FCPEEIY3|Female| 27|      RG277|     Salaried|          X1|     20|            No|             811591|      Yes|      0|        1.0|        Female|\n",
      "|KCE7JSFN|  Male| 31|      RG254|     Salaried|          X1|     31|           Yes|             938754|       No|      0|        0.0|          Male|\n",
      "|EMEEHHBK|  Male| 79|      RG277|        Other|          X3|     57|            No|             832185|      Yes|      0|        0.0|          Male|\n",
      "|UJ2NJKKL|  Male| 33|      RG268|Self_Employed|          X2|     69|            No|             517063|      Yes|      1|        0.0|          Male|\n",
      "|CNGSPYWS|Female| 46|      RG268|        Other|          X3|     97|           Yes|            2282502|       No|      1|        1.0|        Female|\n",
      "|VH7NBNNQ|Female| 59|      RG283|        Other|          X3|     15|           Yes|            2384692|       No|      1|        1.0|        Female|\n",
      "|HDNJXDWC|Female| 65|      RG277|        Other|          X2|     20|            No|             341573|      Yes|      0|        1.0|        Female|\n",
      "|BDOKI4CP|Female| 37|      RG269|        Other|          X1|     63|            No|             633484|      Yes|      0|        1.0|        Female|\n",
      "+--------+------+---+-----------+-------------+------------+-------+--------------+-------------------+---------+-------+-----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "converter = IndexToString(inputCol=\"GenderIndex\", outputCol=\"originalGender\")\n",
    "data = converter.transform(data)\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2_xa6Egj10ts"
   },
   "source": [
    "Давайте аналогично поступим с каналом продаж и типом занятости"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E15ddrq80S3V",
    "outputId": "027c6188-2f8c-41d3-dcec-43526086f588"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+---+-----------+-------------+------------+-------+--------------+-------------------+---------+-------+-----------+--------------+---------------+------------+\n",
      "|      ID|Gender|Age|Region_Code|   Occupation|Channel_Code|Vintage|Credit_Product|Avg_Account_Balance|Is_Active|Is_Lead|GenderIndex|originalGender|OccupationIndex|ChannelIndex|\n",
      "+--------+------+---+-----------+-------------+------------+-------+--------------+-------------------+---------+-------+-----------+--------------+---------------+------------+\n",
      "|NNVBBKZB|Female| 73|      RG268|        Other|          X3|     43|            No|            1045696|       No|      0|        1.0|        Female|            2.0|         1.0|\n",
      "|IDD62UNG|Female| 30|      RG277|     Salaried|          X1|     32|            No|             581988|       No|      0|        1.0|        Female|            1.0|         0.0|\n",
      "|HD3DSEMC|Female| 56|      RG268|Self_Employed|          X3|     26|            No|            1484315|      Yes|      0|        1.0|        Female|            0.0|         1.0|\n",
      "|BF3NC7KV|  Male| 34|      RG270|     Salaried|          X1|     19|            No|             470454|       No|      0|        0.0|          Male|            1.0|         0.0|\n",
      "|TEASRWXV|Female| 30|      RG282|     Salaried|          X1|     33|            No|             886787|       No|      0|        1.0|        Female|            1.0|         0.0|\n",
      "|ACUTYTWS|  Male| 56|      RG261|Self_Employed|          X1|     32|            No|             544163|      Yes|      0|        0.0|          Male|            0.0|         0.0|\n",
      "|ETQCZFEJ|  Male| 62|      RG282|        Other|          X3|     20|            No|            1056750|      Yes|      1|        0.0|          Male|            2.0|         1.0|\n",
      "|JJNJUQMQ|Female| 48|      RG265|Self_Employed|          X3|     13|            No|             444724|      Yes|      0|        1.0|        Female|            0.0|         1.0|\n",
      "|ZMQFYKCB|Female| 40|      RG283|Self_Employed|          X2|     38|            No|            1274284|       No|      0|        1.0|        Female|            0.0|         2.0|\n",
      "|NVKTFBA2|Female| 55|      RG268|Self_Employed|          X2|     49|           Yes|            2014239|       No|      0|        1.0|        Female|            0.0|         2.0|\n",
      "|NVC424KZ|  Male| 53|      RG254|Self_Employed|          X3|    123|            No|             980664|      Yes|      0|        0.0|          Male|            0.0|         1.0|\n",
      "|GZ5TMYIR|  Male| 27|      RG270|Self_Employed|          X1|     14|           Yes|             502787|       No|      0|        0.0|          Male|            0.0|         0.0|\n",
      "|FCPEEIY3|Female| 27|      RG277|     Salaried|          X1|     20|            No|             811591|      Yes|      0|        1.0|        Female|            1.0|         0.0|\n",
      "|KCE7JSFN|  Male| 31|      RG254|     Salaried|          X1|     31|           Yes|             938754|       No|      0|        0.0|          Male|            1.0|         0.0|\n",
      "|EMEEHHBK|  Male| 79|      RG277|        Other|          X3|     57|            No|             832185|      Yes|      0|        0.0|          Male|            2.0|         1.0|\n",
      "|UJ2NJKKL|  Male| 33|      RG268|Self_Employed|          X2|     69|            No|             517063|      Yes|      1|        0.0|          Male|            0.0|         2.0|\n",
      "|CNGSPYWS|Female| 46|      RG268|        Other|          X3|     97|           Yes|            2282502|       No|      1|        1.0|        Female|            2.0|         1.0|\n",
      "|VH7NBNNQ|Female| 59|      RG283|        Other|          X3|     15|           Yes|            2384692|       No|      1|        1.0|        Female|            2.0|         1.0|\n",
      "|HDNJXDWC|Female| 65|      RG277|        Other|          X2|     20|            No|             341573|      Yes|      0|        1.0|        Female|            2.0|         2.0|\n",
      "|BDOKI4CP|Female| 37|      RG269|        Other|          X1|     63|            No|             633484|      Yes|      0|        1.0|        Female|            2.0|         0.0|\n",
      "+--------+------+---+-----------+-------------+------------+-------+--------------+-------------------+---------+-------+-----------+--------------+---------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "occupation_indexer = StringIndexer(inputCol=\"Occupation\", outputCol=\"OccupationIndex\")\n",
    "occupation_indexer = occupation_indexer.fit(data)\n",
    "data = occupation_indexer.transform(data)\n",
    "\n",
    "channel_indexer = StringIndexer(inputCol=\"Channel_Code\", outputCol=\"ChannelIndex\")\n",
    "channel_indexer = channel_indexer.fit(data)\n",
    "data = channel_indexer.transform(data)\n",
    "\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n9bcgggI2xqK",
    "outputId": "39f1ac90-e245-4d75-d396-11057ac6ab33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Occupation len = 4, Channel_code len = 4\n"
     ]
    }
   ],
   "source": [
    "print(f'Occupation len = {len(occupation_indexer.labels)}, Channel_code len = {len(channel_indexer.labels)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vqftb6C43Fsw"
   },
   "source": [
    "Тут по 4 категории, что самое простое, что приходит в голову? Правильно - OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VCeoucMX3NpG",
    "outputId": "a121de69-95ae-4838-b603-e862ffed2408"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+---+-----------+-------------+------------+-------+--------------+-------------------+---------+-------+-----------+--------------+---------------+------------+----------------+-------------+\n",
      "|      ID|Gender|Age|Region_Code|   Occupation|Channel_Code|Vintage|Credit_Product|Avg_Account_Balance|Is_Active|Is_Lead|GenderIndex|originalGender|OccupationIndex|ChannelIndex|OccupationVector|   ChannelVec|\n",
      "+--------+------+---+-----------+-------------+------------+-------+--------------+-------------------+---------+-------+-----------+--------------+---------------+------------+----------------+-------------+\n",
      "|NNVBBKZB|Female| 73|      RG268|        Other|          X3|     43|            No|            1045696|       No|      0|        1.0|        Female|            2.0|         1.0|   (3,[2],[1.0])|(3,[1],[1.0])|\n",
      "|IDD62UNG|Female| 30|      RG277|     Salaried|          X1|     32|            No|             581988|       No|      0|        1.0|        Female|            1.0|         0.0|   (3,[1],[1.0])|(3,[0],[1.0])|\n",
      "|HD3DSEMC|Female| 56|      RG268|Self_Employed|          X3|     26|            No|            1484315|      Yes|      0|        1.0|        Female|            0.0|         1.0|   (3,[0],[1.0])|(3,[1],[1.0])|\n",
      "|BF3NC7KV|  Male| 34|      RG270|     Salaried|          X1|     19|            No|             470454|       No|      0|        0.0|          Male|            1.0|         0.0|   (3,[1],[1.0])|(3,[0],[1.0])|\n",
      "|TEASRWXV|Female| 30|      RG282|     Salaried|          X1|     33|            No|             886787|       No|      0|        1.0|        Female|            1.0|         0.0|   (3,[1],[1.0])|(3,[0],[1.0])|\n",
      "|ACUTYTWS|  Male| 56|      RG261|Self_Employed|          X1|     32|            No|             544163|      Yes|      0|        0.0|          Male|            0.0|         0.0|   (3,[0],[1.0])|(3,[0],[1.0])|\n",
      "|ETQCZFEJ|  Male| 62|      RG282|        Other|          X3|     20|            No|            1056750|      Yes|      1|        0.0|          Male|            2.0|         1.0|   (3,[2],[1.0])|(3,[1],[1.0])|\n",
      "|JJNJUQMQ|Female| 48|      RG265|Self_Employed|          X3|     13|            No|             444724|      Yes|      0|        1.0|        Female|            0.0|         1.0|   (3,[0],[1.0])|(3,[1],[1.0])|\n",
      "|ZMQFYKCB|Female| 40|      RG283|Self_Employed|          X2|     38|            No|            1274284|       No|      0|        1.0|        Female|            0.0|         2.0|   (3,[0],[1.0])|(3,[2],[1.0])|\n",
      "|NVKTFBA2|Female| 55|      RG268|Self_Employed|          X2|     49|           Yes|            2014239|       No|      0|        1.0|        Female|            0.0|         2.0|   (3,[0],[1.0])|(3,[2],[1.0])|\n",
      "|NVC424KZ|  Male| 53|      RG254|Self_Employed|          X3|    123|            No|             980664|      Yes|      0|        0.0|          Male|            0.0|         1.0|   (3,[0],[1.0])|(3,[1],[1.0])|\n",
      "|GZ5TMYIR|  Male| 27|      RG270|Self_Employed|          X1|     14|           Yes|             502787|       No|      0|        0.0|          Male|            0.0|         0.0|   (3,[0],[1.0])|(3,[0],[1.0])|\n",
      "|FCPEEIY3|Female| 27|      RG277|     Salaried|          X1|     20|            No|             811591|      Yes|      0|        1.0|        Female|            1.0|         0.0|   (3,[1],[1.0])|(3,[0],[1.0])|\n",
      "|KCE7JSFN|  Male| 31|      RG254|     Salaried|          X1|     31|           Yes|             938754|       No|      0|        0.0|          Male|            1.0|         0.0|   (3,[1],[1.0])|(3,[0],[1.0])|\n",
      "|EMEEHHBK|  Male| 79|      RG277|        Other|          X3|     57|            No|             832185|      Yes|      0|        0.0|          Male|            2.0|         1.0|   (3,[2],[1.0])|(3,[1],[1.0])|\n",
      "|UJ2NJKKL|  Male| 33|      RG268|Self_Employed|          X2|     69|            No|             517063|      Yes|      1|        0.0|          Male|            0.0|         2.0|   (3,[0],[1.0])|(3,[2],[1.0])|\n",
      "|CNGSPYWS|Female| 46|      RG268|        Other|          X3|     97|           Yes|            2282502|       No|      1|        1.0|        Female|            2.0|         1.0|   (3,[2],[1.0])|(3,[1],[1.0])|\n",
      "|VH7NBNNQ|Female| 59|      RG283|        Other|          X3|     15|           Yes|            2384692|       No|      1|        1.0|        Female|            2.0|         1.0|   (3,[2],[1.0])|(3,[1],[1.0])|\n",
      "|HDNJXDWC|Female| 65|      RG277|        Other|          X2|     20|            No|             341573|      Yes|      0|        1.0|        Female|            2.0|         2.0|   (3,[2],[1.0])|(3,[2],[1.0])|\n",
      "|BDOKI4CP|Female| 37|      RG269|        Other|          X1|     63|            No|             633484|      Yes|      0|        1.0|        Female|            2.0|         0.0|   (3,[2],[1.0])|(3,[0],[1.0])|\n",
      "+--------+------+---+-----------+-------------+------------+-------+--------------+-------------------+---------+-------+-----------+--------------+---------------+------------+----------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ohe_encoder = OneHotEncoder(inputCols=[\"OccupationIndex\", \"ChannelIndex\"],\n",
    "                            outputCols=[\"OccupationVector\", \"ChannelVec\"])\n",
    "ohe_encoder = ohe_encoder.fit(data)\n",
    "data = ohe_encoder.transform(data)\n",
    "\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v994SMld4PeY",
    "outputId": "6ea9ea55-e943-49c5-f96c-97e055a7ae95"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 4]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe_encoder.categorySizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XZgkq6G05PSh"
   },
   "source": [
    "Странный формат, не правда ли? Все из-за того, что тут у нас SparseVector\n",
    "\n",
    " На 4 категории нужен вектор размерности 3, а дальше храним позицию и 1 там, где нужная категория"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U0WwEjcR40px",
    "outputId": "ffe39d49-6d24-4324-d360-f007c88466cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(OccupationVector=SparseVector(3, {2: 1.0}))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.select(col('OccupationVector')).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q5A4TwCYyl9G"
   },
   "source": [
    "Теперь все надо собрать в одну структуру, чтобы можно было анализировать данные и строить модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "FvGBOfFovMQs"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U2QozLTxxe6k",
    "outputId": "c8d96dbf-03de-4a2f-d0d2-60ab586dba5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+---+-----------+-------------+------------+-------+--------------+-------------------+---------+-------+-----------+--------------+---------------+------------+----------------+-------------+\n",
      "|      ID|Gender|Age|Region_Code|   Occupation|Channel_Code|Vintage|Credit_Product|Avg_Account_Balance|Is_Active|Is_Lead|GenderIndex|originalGender|OccupationIndex|ChannelIndex|OccupationVector|   ChannelVec|\n",
      "+--------+------+---+-----------+-------------+------------+-------+--------------+-------------------+---------+-------+-----------+--------------+---------------+------------+----------------+-------------+\n",
      "|NNVBBKZB|Female| 73|      RG268|        Other|          X3|     43|            No|            1045696|       No|      0|        1.0|        Female|            2.0|         1.0|   (3,[2],[1.0])|(3,[1],[1.0])|\n",
      "|IDD62UNG|Female| 30|      RG277|     Salaried|          X1|     32|            No|             581988|       No|      0|        1.0|        Female|            1.0|         0.0|   (3,[1],[1.0])|(3,[0],[1.0])|\n",
      "|HD3DSEMC|Female| 56|      RG268|Self_Employed|          X3|     26|            No|            1484315|      Yes|      0|        1.0|        Female|            0.0|         1.0|   (3,[0],[1.0])|(3,[1],[1.0])|\n",
      "|BF3NC7KV|  Male| 34|      RG270|     Salaried|          X1|     19|            No|             470454|       No|      0|        0.0|          Male|            1.0|         0.0|   (3,[1],[1.0])|(3,[0],[1.0])|\n",
      "|TEASRWXV|Female| 30|      RG282|     Salaried|          X1|     33|            No|             886787|       No|      0|        1.0|        Female|            1.0|         0.0|   (3,[1],[1.0])|(3,[0],[1.0])|\n",
      "+--------+------+---+-----------+-------------+------------+-------+--------------+-------------------+---------+-------+-----------+--------------+---------------+------------+----------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "-d3u3pXZwllv"
   },
   "outputs": [],
   "source": [
    "feature_columns = [\n",
    "                   'Age',\n",
    "                   'Vintage',\n",
    "                   'Avg_Account_Balance',\n",
    "                   'GenderIndex',\n",
    "                   'OccupationVector',\n",
    "                   'ChannelVec'                 \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "w8B6wK5qvPI4"
   },
   "outputs": [],
   "source": [
    "df_va = VectorAssembler(inputCols = feature_columns, outputCol = 'features')\n",
    "data = df_va.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IVIiU4qNzl7I",
    "outputId": "d1f55f26-7da7-4e3e-beda-b87f83c9b5e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Region_Code: string (nullable = true)\n",
      " |-- Occupation: string (nullable = true)\n",
      " |-- Channel_Code: string (nullable = true)\n",
      " |-- Vintage: integer (nullable = true)\n",
      " |-- Credit_Product: string (nullable = false)\n",
      " |-- Avg_Account_Balance: integer (nullable = true)\n",
      " |-- Is_Active: string (nullable = true)\n",
      " |-- Is_Lead: integer (nullable = true)\n",
      " |-- GenderIndex: double (nullable = false)\n",
      " |-- originalGender: string (nullable = true)\n",
      " |-- OccupationIndex: double (nullable = false)\n",
      " |-- ChannelIndex: double (nullable = false)\n",
      " |-- OccupationVector: vector (nullable = true)\n",
      " |-- ChannelVec: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iaXUddG1zp_X",
    "outputId": "e992ad31-c115-4f09-fd35-bcf281660b82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+---+-----------+-------------+------------+-------+--------------+-------------------+---------+-------+-----------+--------------+---------------+------------+----------------+-------------+--------------------+\n",
      "|      ID|Gender|Age|Region_Code|   Occupation|Channel_Code|Vintage|Credit_Product|Avg_Account_Balance|Is_Active|Is_Lead|GenderIndex|originalGender|OccupationIndex|ChannelIndex|OccupationVector|   ChannelVec|            features|\n",
      "+--------+------+---+-----------+-------------+------------+-------+--------------+-------------------+---------+-------+-----------+--------------+---------------+------------+----------------+-------------+--------------------+\n",
      "|NNVBBKZB|Female| 73|      RG268|        Other|          X3|     43|            No|            1045696|       No|      0|        1.0|        Female|            2.0|         1.0|   (3,[2],[1.0])|(3,[1],[1.0])|[73.0,43.0,104569...|\n",
      "|IDD62UNG|Female| 30|      RG277|     Salaried|          X1|     32|            No|             581988|       No|      0|        1.0|        Female|            1.0|         0.0|   (3,[1],[1.0])|(3,[0],[1.0])|[30.0,32.0,581988...|\n",
      "|HD3DSEMC|Female| 56|      RG268|Self_Employed|          X3|     26|            No|            1484315|      Yes|      0|        1.0|        Female|            0.0|         1.0|   (3,[0],[1.0])|(3,[1],[1.0])|[56.0,26.0,148431...|\n",
      "|BF3NC7KV|  Male| 34|      RG270|     Salaried|          X1|     19|            No|             470454|       No|      0|        0.0|          Male|            1.0|         0.0|   (3,[1],[1.0])|(3,[0],[1.0])|(10,[0,1,2,5,7],[...|\n",
      "|TEASRWXV|Female| 30|      RG282|     Salaried|          X1|     33|            No|             886787|       No|      0|        1.0|        Female|            1.0|         0.0|   (3,[1],[1.0])|(3,[0],[1.0])|[30.0,33.0,886787...|\n",
      "|ACUTYTWS|  Male| 56|      RG261|Self_Employed|          X1|     32|            No|             544163|      Yes|      0|        0.0|          Male|            0.0|         0.0|   (3,[0],[1.0])|(3,[0],[1.0])|(10,[0,1,2,4,7],[...|\n",
      "|ETQCZFEJ|  Male| 62|      RG282|        Other|          X3|     20|            No|            1056750|      Yes|      1|        0.0|          Male|            2.0|         1.0|   (3,[2],[1.0])|(3,[1],[1.0])|(10,[0,1,2,6,8],[...|\n",
      "|JJNJUQMQ|Female| 48|      RG265|Self_Employed|          X3|     13|            No|             444724|      Yes|      0|        1.0|        Female|            0.0|         1.0|   (3,[0],[1.0])|(3,[1],[1.0])|[48.0,13.0,444724...|\n",
      "|ZMQFYKCB|Female| 40|      RG283|Self_Employed|          X2|     38|            No|            1274284|       No|      0|        1.0|        Female|            0.0|         2.0|   (3,[0],[1.0])|(3,[2],[1.0])|[40.0,38.0,127428...|\n",
      "|NVKTFBA2|Female| 55|      RG268|Self_Employed|          X2|     49|           Yes|            2014239|       No|      0|        1.0|        Female|            0.0|         2.0|   (3,[0],[1.0])|(3,[2],[1.0])|[55.0,49.0,201423...|\n",
      "|NVC424KZ|  Male| 53|      RG254|Self_Employed|          X3|    123|            No|             980664|      Yes|      0|        0.0|          Male|            0.0|         1.0|   (3,[0],[1.0])|(3,[1],[1.0])|(10,[0,1,2,4,8],[...|\n",
      "|GZ5TMYIR|  Male| 27|      RG270|Self_Employed|          X1|     14|           Yes|             502787|       No|      0|        0.0|          Male|            0.0|         0.0|   (3,[0],[1.0])|(3,[0],[1.0])|(10,[0,1,2,4,7],[...|\n",
      "|FCPEEIY3|Female| 27|      RG277|     Salaried|          X1|     20|            No|             811591|      Yes|      0|        1.0|        Female|            1.0|         0.0|   (3,[1],[1.0])|(3,[0],[1.0])|[27.0,20.0,811591...|\n",
      "|KCE7JSFN|  Male| 31|      RG254|     Salaried|          X1|     31|           Yes|             938754|       No|      0|        0.0|          Male|            1.0|         0.0|   (3,[1],[1.0])|(3,[0],[1.0])|(10,[0,1,2,5,7],[...|\n",
      "|EMEEHHBK|  Male| 79|      RG277|        Other|          X3|     57|            No|             832185|      Yes|      0|        0.0|          Male|            2.0|         1.0|   (3,[2],[1.0])|(3,[1],[1.0])|(10,[0,1,2,6,8],[...|\n",
      "|UJ2NJKKL|  Male| 33|      RG268|Self_Employed|          X2|     69|            No|             517063|      Yes|      1|        0.0|          Male|            0.0|         2.0|   (3,[0],[1.0])|(3,[2],[1.0])|(10,[0,1,2,4,9],[...|\n",
      "|CNGSPYWS|Female| 46|      RG268|        Other|          X3|     97|           Yes|            2282502|       No|      1|        1.0|        Female|            2.0|         1.0|   (3,[2],[1.0])|(3,[1],[1.0])|[46.0,97.0,228250...|\n",
      "|VH7NBNNQ|Female| 59|      RG283|        Other|          X3|     15|           Yes|            2384692|       No|      1|        1.0|        Female|            2.0|         1.0|   (3,[2],[1.0])|(3,[1],[1.0])|[59.0,15.0,238469...|\n",
      "|HDNJXDWC|Female| 65|      RG277|        Other|          X2|     20|            No|             341573|      Yes|      0|        1.0|        Female|            2.0|         2.0|   (3,[2],[1.0])|(3,[2],[1.0])|[65.0,20.0,341573...|\n",
      "|BDOKI4CP|Female| 37|      RG269|        Other|          X1|     63|            No|             633484|      Yes|      0|        1.0|        Female|            2.0|         0.0|   (3,[2],[1.0])|(3,[0],[1.0])|[37.0,63.0,633484...|\n",
      "+--------+------+---+-----------+-------------+------------+-------+--------------+-------------------+---------+-------+-----------+--------------+---------------+------------+----------------+-------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rCWpLx31zh67"
   },
   "source": [
    "В полученном features можно автоматичеки проанализировать все переменные и если у кого-то уникальных значений меньше заданного вами порога, то они автоматичсеки переведутся в индексы при помощи pyspark.ml.feature import VectorIndexer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sDUyHq-CwHRw"
   },
   "source": [
    "**Статистика**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AJdSxnSRwRKv"
   },
   "source": [
    "В ml pyspark есть некоторые статистические методы, которые можно использовать для анализа\n",
    "\n",
    "Корреляция"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "bLh7XX3GpCtZ"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.stat import Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yopY40AAwzhq",
    "outputId": "55adae33-17c2-43a3-d2b3-28ad2d7711f5"
   },
   "outputs": [],
   "source": [
    "corr = Correlation.corr(data, 'features', method='pearson').collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b5NJYBqi0o4J",
    "outputId": "159247e6-31ca-40ac-d17d-ee13e2bee447"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseMatrix(10, 10, [1.0, 0.6312, 0.1452, -0.1521, 0.1527, -0.5632, 0.3948, -0.6646, ..., 0.0102, -0.116, 0.2933, -0.3238, 0.0005, -0.5272, -0.3843, 1.0], False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kdYSH7Hg1Fwm",
    "outputId": "b0c09b6d-1521-455e-e713-00735814462b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00000000e+00,  6.31242411e-01,  1.45232189e-01,\n",
       "        -1.52075940e-01,  1.52651808e-01, -5.63226982e-01,\n",
       "         3.94834177e-01, -6.64600051e-01,  4.56338440e-01,\n",
       "         2.73153253e-01],\n",
       "       [ 6.31242411e-01,  1.00000000e+00,  1.67433481e-01,\n",
       "        -1.46379743e-01,  2.21023818e-01, -4.10109383e-01,\n",
       "         1.55662661e-01, -5.71828453e-01,  5.38828562e-01,\n",
       "         1.44931244e-01],\n",
       "       [ 1.45232189e-01,  1.67433481e-01,  1.00000000e+00,\n",
       "        -2.24772031e-02,  3.46714040e-03, -7.16906860e-02,\n",
       "         6.03874569e-02, -9.81785292e-02,  1.06905544e-01,\n",
       "         1.01634033e-02],\n",
       "       [-1.52075940e-01, -1.46379743e-01, -2.24772031e-02,\n",
       "         1.00000000e+00, -8.58626857e-02,  1.22439249e-01,\n",
       "        -2.58175123e-02,  1.84372479e-01, -8.07817702e-02,\n",
       "        -1.16018433e-01],\n",
       "       [ 1.52651808e-01,  2.21023818e-01,  3.46714040e-03,\n",
       "        -8.58626857e-02,  1.00000000e+00, -5.37283514e-01,\n",
       "        -5.27660791e-01, -4.34990948e-01,  1.63662837e-01,\n",
       "         2.93303563e-01],\n",
       "       [-5.63226982e-01, -4.10109383e-01, -7.16906860e-02,\n",
       "         1.22439249e-01, -5.37283514e-01,  1.00000000e+00,\n",
       "        -4.07017379e-01,  5.90747136e-01, -3.07398921e-01,\n",
       "        -3.23819864e-01],\n",
       "       [ 3.94834177e-01,  1.55662661e-01,  6.03874569e-02,\n",
       "        -2.58175123e-02, -5.27660791e-01, -4.07017379e-01,\n",
       "         1.00000000e+00, -1.04278488e-01,  1.19212770e-01,\n",
       "         4.66283346e-04],\n",
       "       [-6.64600051e-01, -5.71828453e-01, -9.81785292e-02,\n",
       "         1.84372479e-01, -4.34990948e-01,  5.90747136e-01,\n",
       "        -1.04278488e-01,  1.00000000e+00, -5.32458671e-01,\n",
       "        -5.27158389e-01],\n",
       "       [ 4.56338440e-01,  5.38828562e-01,  1.06905544e-01,\n",
       "        -8.07817702e-02,  1.63662837e-01, -3.07398921e-01,\n",
       "         1.19212770e-01, -5.32458671e-01,  1.00000000e+00,\n",
       "        -3.84310850e-01],\n",
       "       [ 2.73153253e-01,  1.44931244e-01,  1.01634033e-02,\n",
       "        -1.16018433e-01,  2.93303563e-01, -3.23819864e-01,\n",
       "         4.66283346e-04, -5.27158389e-01, -3.84310850e-01,\n",
       "         1.00000000e+00]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr.toArray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UaW05KoO1QZ9"
   },
   "source": [
    "Можно вычислить корреляцию спирмена"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BYUenSBo1P1D",
    "outputId": "e59acca9-04d3-46c4-9b0b-7d00a03308c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00000000e+00,  6.52477119e-01,  1.78395617e-01,\n",
       "        -1.66276503e-01,  2.50479037e-01, -5.94192974e-01,\n",
       "         3.16280765e-01, -7.14324073e-01,  4.68523607e-01,\n",
       "         3.11874367e-01],\n",
       "       [ 6.52477119e-01,  1.00000000e+00,  1.98039737e-01,\n",
       "        -1.37241231e-01,  2.26617372e-01, -4.03612329e-01,\n",
       "         1.44248315e-01, -5.43361590e-01,  4.88850315e-01,\n",
       "         1.86509197e-01],\n",
       "       [ 1.78395617e-01,  1.98039737e-01,  1.00000000e+00,\n",
       "        -3.35726184e-02,  1.74003362e-02, -9.65169583e-02,\n",
       "         6.80005979e-02, -1.34528255e-01,  1.34941462e-01,\n",
       "         2.41122172e-02],\n",
       "       [-1.66276503e-01, -1.37241231e-01, -3.35726184e-02,\n",
       "         1.00000000e+00, -8.58626857e-02,  1.22439249e-01,\n",
       "        -2.58175123e-02,  1.84372479e-01, -8.07817702e-02,\n",
       "        -1.16018433e-01],\n",
       "       [ 2.50479037e-01,  2.26617372e-01,  1.74003362e-02,\n",
       "        -8.58626857e-02,  1.00000000e+00, -5.37283514e-01,\n",
       "        -5.27660791e-01, -4.34990948e-01,  1.63662837e-01,\n",
       "         2.93303563e-01],\n",
       "       [-5.94192974e-01, -4.03612329e-01, -9.65169583e-02,\n",
       "         1.22439249e-01, -5.37283514e-01,  1.00000000e+00,\n",
       "        -4.07017379e-01,  5.90747136e-01, -3.07398921e-01,\n",
       "        -3.23819864e-01],\n",
       "       [ 3.16280765e-01,  1.44248315e-01,  6.80005979e-02,\n",
       "        -2.58175123e-02, -5.27660791e-01, -4.07017379e-01,\n",
       "         1.00000000e+00, -1.04278488e-01,  1.19212770e-01,\n",
       "         4.66283346e-04],\n",
       "       [-7.14324073e-01, -5.43361590e-01, -1.34528255e-01,\n",
       "         1.84372479e-01, -4.34990948e-01,  5.90747136e-01,\n",
       "        -1.04278488e-01,  1.00000000e+00, -5.32458671e-01,\n",
       "        -5.27158389e-01],\n",
       "       [ 4.68523607e-01,  4.88850315e-01,  1.34941462e-01,\n",
       "        -8.07817702e-02,  1.63662837e-01, -3.07398921e-01,\n",
       "         1.19212770e-01, -5.32458671e-01,  1.00000000e+00,\n",
       "        -3.84310850e-01],\n",
       "       [ 3.11874367e-01,  1.86509197e-01,  2.41122172e-02,\n",
       "        -1.16018433e-01,  2.93303563e-01, -3.23819864e-01,\n",
       "         4.66283346e-04, -5.27158389e-01, -3.84310850e-01,\n",
       "         1.00000000e+00]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = Correlation.corr(data, 'features', method='spearman').collect()[0][0]\n",
    "corr.toArray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y_5PVUlY2F5Y"
   },
   "source": [
    "Можно использовать хи-квадрат тест для оценки независимости каждой переменной в features относительно целевого признака, но этот тест для категориальных переменных, поэтому для примера на одной фиче"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "qKDaZAqo2qcx"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.stat import ChiSquareTest, KolmogorovSmirnovTest, Summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NKv6rl6L2uD3",
    "outputId": "a507f56e-551a-4552-ebc1-6b86bc5f56a4"
   },
   "outputs": [],
   "source": [
    "r = ChiSquareTest.test(data, \"OccupationVector\", \"Is_Lead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zs8p9cYz232n",
    "outputId": "bd20e3a5-29ce-44a8-e05d-f8c1a88fc29c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+--------------------+\n",
      "|             pValues|degreesOfFreedom|          statistics|\n",
      "+--------------------+----------------+--------------------+\n",
      "|[0.0,0.0,1.161583...|       [1, 1, 1]|[1420.86324574575...|\n",
      "+--------------------+----------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L5bWlEXS48xD"
   },
   "source": [
    "KS-тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AQxAgsUx6NVR",
    "outputId": "3b63c94c-f476-4ffb-8c88-56feb124c6f8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(mean_Age=43.85630684708516, std_Age=14.828671804648)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.select(\n",
    "    F.mean(col('Age')).alias('mean_Age'),\n",
    "    F.stddev(col('Age')).alias('std_Age')\n",
    ").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IoppdTHa46tZ",
    "outputId": "cfb0aefe-7315-410f-a911-a1fb0f63057b"
   },
   "outputs": [],
   "source": [
    "ks = KolmogorovSmirnovTest.test(data, 'Age', 'norm', 44, 15).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y_f8r3Lg7KW5",
    "outputId": "0893e2a2-245d-4ed6-9024-5ed4395cd464"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(pValue=2.045950076023928e-10, statistic=0.12561207843265512)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8brAdeEf7oxC"
   },
   "source": [
    "Еще можно посчитать разные статистики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yYYVSXeO7s5s",
    "outputId": "b0b72ca4-13f2-4ff9-e2cb-9b91e8f53bfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|aggregate_metrics(features, 1.0)                                                                                                                                                                         |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|{[43.8563068470851,46.95914131651203,1128403.1010194335,0.4538732322718486,0.4105646556109472,0.29300640960423235,0.2855753382846678,0.42208973445925324,0.2796296673110184,0.27561705158205313], 245725}|\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summarizer = Summarizer.metrics(\"mean\", \"count\")\n",
    "data.select(summarizer.summary(data.features)).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YKcAS-ZySbmv"
   },
   "source": [
    "**Работа с фичами**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gb2La8IGSfy2"
   },
   "source": [
    "Квантизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "UU52as0DSfM3"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import QuantileDiscretizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JwLM1tzZTCpM"
   },
   "source": [
    "Обучаем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "eLEqod7ASm_p"
   },
   "outputs": [],
   "source": [
    "discretizer = QuantileDiscretizer(numBuckets=5, inputCol=\"Age\", outputCol=\"Age_quant\")\n",
    "discretizer = discretizer.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "DJEUHC2CTE1Z"
   },
   "outputs": [],
   "source": [
    "data = discretizer.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BzA9F_8wUZzD",
    "outputId": "62268aac-0e56-4b57-d7ba-9ddf89032207"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+-------+-----+\n",
      "|Age_quant|min_age|max_age|count|\n",
      "+---------+-------+-------+-----+\n",
      "|      0.0|     23|     28|43790|\n",
      "|      1.0|     29|     35|52017|\n",
      "|      2.0|     36|     46|46007|\n",
      "|      3.0|     47|     55|50808|\n",
      "|      4.0|     56|     85|53103|\n",
      "+---------+-------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select('Age', 'Age_quant')\\\n",
    "    .groupby('Age_quant').agg(\n",
    "        F.min('Age').alias('min_age'),\n",
    "        F.max('Age').alias('max_age'),\n",
    "        F.count('Age').alias('count')\n",
    "    )\\\n",
    "    .orderBy('Age_quant')\\\n",
    "    .show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4MCJmjnVWnYo"
   },
   "source": [
    "Заполнить пропуски можно через Imputer\n",
    "\n",
    "Заполнять пропуски умеет только для числовых переменных, поэтому попробуем на игрушечном примере\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "tQLJUwVnXHGg"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tnLtSJgXWrnK",
    "outputId": "8dab73a1-b985-4b5b-f908-ecf2095937ff"
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o561.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 6 in stage 79.0 failed 1 times, most recent failure: Lost task 6.0 in stage 79.0 (TID 160) (DESKTOP-TS0U1T0 executor driver): org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:203)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(Unknown Source)\r\n\tat java.net.AbstractPlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.PlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.ServerSocket.implAccept(Unknown Source)\r\n\tat java.net.ServerSocket.accept(Unknown Source)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:190)\r\n\t... 34 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\nCaused by: org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:203)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(Unknown Source)\r\n\tat java.net.AbstractPlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.PlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.ServerSocket.implAccept(Unknown Source)\r\n\tat java.net.ServerSocket.accept(Unknown Source)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:190)\r\n\t... 34 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#стратегия может быть 'mean', 'median', 'mode'\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#через setMissingValue(0.0) можно сказать, что пропуски - это 0\u001b[39;00m\n\u001b[0;32m     11\u001b[0m imputer \u001b[38;5;241m=\u001b[39m Imputer(inputCols\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m], outputCols\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout_a\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout_b\u001b[39m\u001b[38;5;124m\"\u001b[39m], strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m imputer \u001b[38;5;241m=\u001b[39m \u001b[43mimputer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m imputer\u001b[38;5;241m.\u001b[39mtransform(df)\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32m~\\Desktop\\pyspark\\venv\\Lib\\site-packages\\pyspark\\ml\\base.py:205\u001b[0m, in \u001b[0;36mEstimator.fit\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_fit(dataset)\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be either a param map or a list/tuple of param maps, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    209\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params)\n\u001b[0;32m    210\u001b[0m     )\n",
      "File \u001b[1;32m~\\Desktop\\pyspark\\venv\\Lib\\site-packages\\pyspark\\ml\\wrapper.py:381\u001b[0m, in \u001b[0;36mJavaEstimator._fit\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset: DataFrame) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m JM:\n\u001b[1;32m--> 381\u001b[0m     java_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_java\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    382\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_model(java_model)\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_copyValues(model)\n",
      "File \u001b[1;32m~\\Desktop\\pyspark\\venv\\Lib\\site-packages\\pyspark\\ml\\wrapper.py:378\u001b[0m, in \u001b[0;36mJavaEstimator._fit_java\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_java_obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transfer_params_to_java()\n\u001b[1;32m--> 378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_java_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\pyspark\\venv\\Lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\Desktop\\pyspark\\venv\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32m~\\Desktop\\pyspark\\venv\\Lib\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o561.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 6 in stage 79.0 failed 1 times, most recent failure: Lost task 6.0 in stage 79.0 (TID 160) (DESKTOP-TS0U1T0 executor driver): org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:203)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(Unknown Source)\r\n\tat java.net.AbstractPlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.PlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.ServerSocket.implAccept(Unknown Source)\r\n\tat java.net.ServerSocket.accept(Unknown Source)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:190)\r\n\t... 34 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\nCaused by: org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:203)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(Unknown Source)\r\n\tat java.net.AbstractPlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.PlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.ServerSocket.implAccept(Unknown Source)\r\n\tat java.net.ServerSocket.accept(Unknown Source)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:190)\r\n\t... 34 more\r\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([\n",
    "    (1.0, float(\"nan\")),\n",
    "    (2.0, float(\"nan\")),\n",
    "    (float(\"nan\"), 3.0),\n",
    "    (4.0, 4.0),\n",
    "    (5.0, 5.0)\n",
    "], [\"a\", \"b\"])\n",
    "\n",
    "#стратегия может быть 'mean', 'median', 'mode'\n",
    "#через setMissingValue(0.0) можно сказать, что пропуски - это 0\n",
    "imputer = Imputer(inputCols=[\"a\", \"b\"], outputCols=[\"out_a\", \"out_b\"], strategy='mean')\n",
    "imputer = imputer.fit(df)\n",
    "imputer.transform(df).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZhnOCVaJN4TE"
   },
   "source": [
    "**Pipeline**\n",
    "\n",
    "Как и в scikit-learn можно создавать пайплайны обработки данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iA70rsPgYIPb"
   },
   "source": [
    "Мы много делали преобразований, давайте соберем все в 1 пайплайн"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EQSjY7OGNuV5"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2F3RrpODOSdK"
   },
   "outputs": [],
   "source": [
    "#string в индесы\n",
    "gender_indexer = StringIndexer(inputCol=\"Gender\", outputCol=\"GenderIndex\")\n",
    "occupation_indexer = StringIndexer(inputCol=\"Occupation\", outputCol=\"OccupationIndex\")\n",
    "channel_indexer = StringIndexer(inputCol=\"Channel_Code\", outputCol=\"ChannelIndex\")\n",
    "\n",
    "#OHE\n",
    "ohe_encoder = OneHotEncoder(inputCols=[\"OccupationIndex\", \"ChannelIndex\"],\n",
    "                        outputCols=[\"OccupationVector\", \"ChannelVec\"])\n",
    "\n",
    "#квантизация\n",
    "discretizer = QuantileDiscretizer(numBuckets=5, inputCol=\"Age\", outputCol=\"Age_quant\")\n",
    "\n",
    "#собираем все в вектор\n",
    "feature_columns = [\n",
    "                   'Age',\n",
    "                   'Vintage',\n",
    "                   'Avg_Account_Balance',\n",
    "                   'GenderIndex',\n",
    "                   'OccupationVector',\n",
    "                   'ChannelVec',\n",
    "                   'Age_quant'                 \n",
    "]\n",
    "vector_assembler = VectorAssembler(inputCols = feature_columns, outputCol = 'features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XFC0GDkKPOaf"
   },
   "source": [
    "собираем все в пайплайн"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "01A49vw-PBUX"
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[\n",
    "                           gender_indexer,\n",
    "                           occupation_indexer,\n",
    "                           channel_indexer,\n",
    "                           ohe_encoder,\n",
    "                           discretizer,\n",
    "                           vector_assembler,\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QsvoIzWBPoL8"
   },
   "source": [
    "Давайте заново загрузим данные и сделаем трансформацию\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5w32Zu8CPnjW"
   },
   "outputs": [],
   "source": [
    "data = spark.read.csv('credit_card_data.csv', header=True, inferSchema=True)\n",
    "data = data.fillna({'Credit_Product': 'No'})\n",
    "pipeline = pipeline.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sZL7qvxlQMQF"
   },
   "outputs": [],
   "source": [
    "transformed_data = pipeline.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q2FxS5ahYcew",
    "outputId": "d68a12f2-4231-43a0-864d-5817d59fca26"
   },
   "outputs": [],
   "source": [
    "transformed_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wAxYmxspQRtg",
    "outputId": "9ef0878b-6807-4a9e-b305-c52d8ac1f424"
   },
   "outputs": [],
   "source": [
    "transformed_data.select('Is_Lead', 'features').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fQ3Hd-9zZfqS"
   },
   "source": [
    "**Модельки**\n",
    "\n",
    "Пора нам уже что-то обучить, начнем с логрега"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yPjuQR3nZmNP"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression, LogisticRegressionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1E6G5HuFZ11p"
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(featuresCol='features', labelCol='Is_Lead', predictionCol='prediction',\n",
    "                        maxIter=100, probabilityCol='proba')\n",
    "\n",
    "lr = lr.fit(transformed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q-rzIwuDws9m"
   },
   "source": [
    "Сохраним"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B_7j3DSkwfzv"
   },
   "outputs": [],
   "source": [
    "lr.save('logreg_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UNXljB3Bw9ui"
   },
   "source": [
    "Загрузка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DNPT1BVAwwdj"
   },
   "outputs": [],
   "source": [
    "lr2 = LogisticRegressionModel.load('logreg_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kKQWHwILb9ZG"
   },
   "source": [
    "Коэффициенты и метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_0UWzsFwav6u",
    "outputId": "a81dfa5e-0aa7-4901-bed3-0a92e7d272cd"
   },
   "outputs": [],
   "source": [
    "print(\"Coefficients: \" + str(lr.coefficients))\n",
    "print(\"Intercept: \" + str(lr.intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y7G91sTrxQbs",
    "outputId": "20b65b16-e183-4119-fc00-0dc1bfd52da4"
   },
   "outputs": [],
   "source": [
    "print(\"Coefficients: \" + str(lr2.coefficients))\n",
    "print(\"Intercept: \" + str(lr2.intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K7gmjDu4blD1",
    "outputId": "bcd7d8f2-62da-4184-883c-81a7e0fc5943"
   },
   "outputs": [],
   "source": [
    "print(f'ROC_AUC = {lr.summary.areaUnderROC}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SeL7Hy0Wa7xC",
    "outputId": "73c4716c-e92a-4682-b5d2-c51b353b952c"
   },
   "outputs": [],
   "source": [
    "lr.summary.recallByLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "supy8ehjdDkz",
    "outputId": "43f57a19-6e52-4f8b-9399-5c146cdc9021"
   },
   "outputs": [],
   "source": [
    "lr.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qt98_rd6cGqJ",
    "outputId": "29097d5f-39d6-4c24-e747-fc8e428ae6a2"
   },
   "outputs": [],
   "source": [
    "lr.transform(transformed_data.select('Is_Lead', 'features')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ipn37OYZfe_8"
   },
   "source": [
    "**Подбор параметров**\n",
    "\n",
    "Тут нет всяких hyperopt, optuna...есть стандартная кросс-валидация и поиск по сетке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xm9NGSM-fwSZ"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit, CrossValidator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "akrk6N6HgWFa"
   },
   "source": [
    "Для этого соберем все в пайплайн. Можно было \"вложить\" старый пайплайн в новый, но соберем все с самого начала"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A4SVMvaQgYfk"
   },
   "outputs": [],
   "source": [
    "#string в индесы\n",
    "gender_indexer = StringIndexer(inputCol=\"Gender\", outputCol=\"GenderIndex\")\n",
    "occupation_indexer = StringIndexer(inputCol=\"Occupation\", outputCol=\"OccupationIndex\")\n",
    "channel_indexer = StringIndexer(inputCol=\"Channel_Code\", outputCol=\"ChannelIndex\")\n",
    "\n",
    "#OHE\n",
    "ohe_encoder = OneHotEncoder(inputCols=[\"OccupationIndex\", \"ChannelIndex\"],\n",
    "                        outputCols=[\"OccupationVector\", \"ChannelVec\"])\n",
    "\n",
    "#квантизация\n",
    "discretizer = QuantileDiscretizer(numBuckets=5, inputCol=\"Age\", outputCol=\"Age_quant\")\n",
    "\n",
    "#собираем все в вектор\n",
    "feature_columns = [\n",
    "                   'Age',\n",
    "                   'Vintage',\n",
    "                   'Avg_Account_Balance',\n",
    "                   'GenderIndex',\n",
    "                   'OccupationVector',\n",
    "                   'ChannelVec',\n",
    "                   'Age_quant'                 \n",
    "]\n",
    "vector_assembler = VectorAssembler(inputCols = feature_columns, outputCol = 'features')\n",
    "\n",
    "lr = LogisticRegression(featuresCol='features', labelCol='Is_Lead', predictionCol='prediction',\n",
    "                        maxIter=100, probabilityCol='proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rn8cK_B4gKRd"
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[\n",
    "                           gender_indexer,\n",
    "                           occupation_indexer,\n",
    "                           channel_indexer,\n",
    "                           ohe_encoder,\n",
    "                           discretizer,\n",
    "                           vector_assembler,\n",
    "                           lr\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T9gENnbniGi4"
   },
   "source": [
    "Сетка параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JC9hlYpFgtru"
   },
   "outputs": [],
   "source": [
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(discretizer.numBuckets, [5, 10]) \\\n",
    "    .addGrid(lr.maxIter, [10, 20]) \\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9pjHOyAbikU4"
   },
   "source": [
    "Разобьем данные на train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9fLrqVlwim3-"
   },
   "outputs": [],
   "source": [
    "train, test = data.randomSplit([0.7, 0.3], seed=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vUu8wO5cjEQO"
   },
   "source": [
    "Описываем стратегию кросс-валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ppn-9HE1iNWN"
   },
   "outputs": [],
   "source": [
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(rawPredictionCol='rawPrediction',\n",
    "                                                                  labelCol='Is_Lead', metricName='areaUnderROC'),\n",
    "                          numFolds=2,\n",
    "                          parallelism=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UxsvDyaqkEvM"
   },
   "source": [
    "Поняем сетку. Знаю, перебор по сетке прошлый век, но что поделать)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eLZZWrBoigSx"
   },
   "outputs": [],
   "source": [
    "cvModel = crossval.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n2rQLkQ4lqUY",
    "outputId": "fd9245d1-0971-4f0e-836d-a1d0ef5f7cc4"
   },
   "outputs": [],
   "source": [
    "cvModel.avgMetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_KB9cRqbqRwu"
   },
   "source": [
    "Параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PfkNIaY2qThi",
    "outputId": "dd1cdee7-13f0-417d-996c-b2ebd72694c7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(cvModel.getEstimatorParamMaps()[np.argmax(cvModel.avgMetrics)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AOWVYH99qeFR"
   },
   "source": [
    "Сделаем предикт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JbsJtmC3l1KN"
   },
   "outputs": [],
   "source": [
    "test_pred = cvModel.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E-PfseCjm7Ih",
    "outputId": "63e6223d-3ced-4eaa-99bf-c69ba2b32acb"
   },
   "outputs": [],
   "source": [
    "test_pred.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LA5pbziMoRDT"
   },
   "source": [
    "Проверим модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eO7WOldKoEqK"
   },
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol='rawPrediction',\n",
    "                                          labelCol='Is_Lead', metricName='areaUnderROC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5bH_zffaoLJy",
    "outputId": "83cd9b52-9a0c-4074-bdde-d3f8389f36ca"
   },
   "outputs": [],
   "source": [
    "evaluator.evaluate(test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KiOvzq7Sqi8d"
   },
   "source": [
    "Сохраним пайплайн"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DSYb-f_AqlFL"
   },
   "outputs": [],
   "source": [
    "cvModel.write().save('model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sv0etfqprdpj"
   },
   "source": [
    "вместо кросс-валидации можно взять TrainValidationSplit для подбора параметров, это train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9aco7h88Jv3m"
   },
   "source": [
    "**Ваша любимая домашка**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hzvvR75kJ4v8"
   },
   "source": [
    "Кто проходил курс GPU прекрасно знают датасет.\n",
    "Данные находятся в файле Train_Set_90621.csv\n",
    "Amount Defaulted - эту переменную нужно удалить=)\n",
    "\n",
    "Что ожидается? - творчество)\n",
    "\n",
    "    1) Начните с анализа баланса классов, пропусков, статистик при помощи DataFrame API\n",
    "    2) Посомтрите статистики, заполните пропуски при помощи уже MLlib\n",
    "    3) Соберите пайплайн, похожий на наш, где будет обработка данных, обучение моделей и все при помощи Spark\n",
    "    4) Разбейте данные на train/test + реализуйте подбор параметров одним из способов спарка\n",
    "    5) Cохраниет пайплайн на диск\n",
    "    6) Проверьте качество модели на отложенной test выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PySpark_MLlib.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
